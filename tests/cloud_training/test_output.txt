============================= test session starts ==============================
platform linux -- Python 3.10.6, pytest-8.0.0, pluggy-1.4.0 -- /home/parissa/.pyenv/versions/3.10.6/envs/taxifare-env/bin/python3.10
cachedir: .pytest_cache
rootdir: /home/parissa/code/ParissaPeimaniyfard/07-ML-Ops/02-Cloud-training/data-train-in-the-cloud/tests
configfile: pytest_kitt.ini
collecting ... collected 9 items

tests/cloud_training/test_cloud_data.py::TestCloudData::test_big_query_dataset_variable_exists PASSED [ 11%]
tests/cloud_training/test_cloud_data.py::TestCloudData::test_cloud_data_create_dataset PASSED [ 22%]
tests/cloud_training/test_cloud_data.py::TestCloudData::test_cloud_data_create_table PASSED [ 33%]
tests/cloud_training/test_main.py::TestMain::test_route_preprocess PASSED [ 44%]
tests/cloud_training/test_main.py::TestMain::test_route_train[local] FAILED [ 55%]
tests/cloud_training/test_main.py::TestMain::test_route_train[gcs] FAILED [ 66%]
tests/cloud_training/test_main.py::TestMain::test_route_evaluate FAILED  [ 77%]
tests/cloud_training/test_main.py::TestMain::test_route_pred FAILED      [ 88%]
tests/cloud_training/test_vm.py::test_i_am_a_vm FAILED                   [100%]

=================================== FAILURES ===================================
_______________________ TestMain.test_route_train[local] _______________________

self = <tests.cloud_training.test_main.TestMain object at 0x7fe1c89a25c0>
fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]
model_target = 'local'

    @pytest.mark.parametrize('model_target', ['local' , 'gcs'])
    def test_route_train(self, fixture_processed_1k, model_target):
        """Test route train behave as expected, for various context of LOCAL or GCS model storage"""
    
        # 1) SETUP
        old_model_target = os.environ.get("MODEL_TARGET")
        os.environ.update(MODEL_TARGET=model_target)
    
        data_processed_path = Path(LOCAL_DATA_PATH).joinpath("processed",f"processed_{MIN_DATE}_{MAX_DATE}_{DATA_SIZE}.csv")
        data_processed_exists = data_processed_path.is_file()
        if data_processed_exists:
            shutil.copyfile(data_processed_path, f'{data_processed_path}_backup')
            data_processed_path.unlink()
    
        data_processed_fixture_path = "https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/solutions/data_processed_fixture_2009-01-01_2015-01-01_1k.csv"
        os.system(f"curl {data_processed_fixture_path} > {data_processed_path}")
    
        # 2) ACT
        from taxifare.interface.main import train
    
        # Train it from Big Query
>       train(min_date=MIN_DATE, max_date=MAX_DATE, learning_rate=0.01, patience=0)

tests/cloud_training/test_main.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

min_date = '2009-01-01', max_date = '2015-01-01', split_ratio = 0.02
learning_rate = 0.01, batch_size = 256, patience = 0

    def train(
            min_date:str = '2009-01-01',
            max_date:str = '2015-01-01',
            split_ratio: float = 0.02, # 0.02 represents ~ 1 month of validation data on a 2009-2015 train set
            learning_rate=0.0005,
            batch_size = 256,
            patience = 2
        ) -> float:
    
        """
        - Download processed data from your BQ table (or from cache if it exists)
        - Train on the preprocessed dataset (which should be ordered by date)
        - Store training results and model weights
    
        Return val_mae as a float
        """
    
        print(Fore.MAGENTA + "\n‚≠êÔ∏è Use case: train" + Style.RESET_ALL)
        print(Fore.BLUE + "\nLoading preprocessed validation data..." + Style.RESET_ALL)
    
        min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'
        max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'
    
        # Load processed data using `get_data_with_cache` in chronological order
        # Try it out manually on console.cloud.google.com first!
    
        query = f"""
            SELECT * EXEPT(_0)
            FROM {GCP_PROJECT_WAGON}.{BQ_DATASET}.processed_{DATA_SIZE}
            WHERE _0 BETWEEN '{min_date}' AND '{max_date}'
            ORDER BY _0 ASC
        """
        data_processed_cache_path = Path(LOCAL_DATA_PATH).joinpath("processed", f"processed_{min_date}_{max_date}_{DATA_SIZE}.csv")
        data_processed= get_data_with_cache(query=query,
                                        gcp_project= GCP_PROJECT,
                                        cache_path=data_processed_cache_path,
                                        data_has_header=False)
        if data_processed.shape[0] <10:
            print('not enough data to train on')
            return None
    
        # Create (X_train_processed, y_train, X_val_processed, y_val)
        train_length = int(len(data_processed) * (1 - split_ratio))
        data_processed_train = data_processed.iloc[:train_length, :].sample(frac=1).to_numpy()
        data_processed_val = data_processed.iloc[train_length:, :].sample(frac=1).to_numpy()
    
>       X_train_processed = data_processed_train.drop("fare_amount", axis=1)
E       AttributeError: 'numpy.ndarray' object has no attribute 'drop'

taxifare/interface/main.py:113: AttributeError
----------------------------- Captured stdout call -----------------------------
[35m
‚≠êÔ∏è Use case: train[0m
[34m
Loading preprocessed validation data...[0m
[34m
Load data from local CSV...[0m
‚úÖ Data loaded, with shape (447, 66)
----------------------------- Captured stderr call -----------------------------
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  153k  100  153k    0     0  1213k      0 --:--:-- --:--:-- --:--:-- 1231k
________________________ TestMain.test_route_train[gcs] ________________________

self = <tests.cloud_training.test_main.TestMain object at 0x7fe1c89a2770>
fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]
model_target = 'gcs'

    @pytest.mark.parametrize('model_target', ['local' , 'gcs'])
    def test_route_train(self, fixture_processed_1k, model_target):
        """Test route train behave as expected, for various context of LOCAL or GCS model storage"""
    
        # 1) SETUP
        old_model_target = os.environ.get("MODEL_TARGET")
        os.environ.update(MODEL_TARGET=model_target)
    
        data_processed_path = Path(LOCAL_DATA_PATH).joinpath("processed",f"processed_{MIN_DATE}_{MAX_DATE}_{DATA_SIZE}.csv")
        data_processed_exists = data_processed_path.is_file()
        if data_processed_exists:
            shutil.copyfile(data_processed_path, f'{data_processed_path}_backup')
            data_processed_path.unlink()
    
        data_processed_fixture_path = "https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/solutions/data_processed_fixture_2009-01-01_2015-01-01_1k.csv"
        os.system(f"curl {data_processed_fixture_path} > {data_processed_path}")
    
        # 2) ACT
        from taxifare.interface.main import train
    
        # Train it from Big Query
>       train(min_date=MIN_DATE, max_date=MAX_DATE, learning_rate=0.01, patience=0)

tests/cloud_training/test_main.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

min_date = '2009-01-01', max_date = '2015-01-01', split_ratio = 0.02
learning_rate = 0.01, batch_size = 256, patience = 0

    def train(
            min_date:str = '2009-01-01',
            max_date:str = '2015-01-01',
            split_ratio: float = 0.02, # 0.02 represents ~ 1 month of validation data on a 2009-2015 train set
            learning_rate=0.0005,
            batch_size = 256,
            patience = 2
        ) -> float:
    
        """
        - Download processed data from your BQ table (or from cache if it exists)
        - Train on the preprocessed dataset (which should be ordered by date)
        - Store training results and model weights
    
        Return val_mae as a float
        """
    
        print(Fore.MAGENTA + "\n‚≠êÔ∏è Use case: train" + Style.RESET_ALL)
        print(Fore.BLUE + "\nLoading preprocessed validation data..." + Style.RESET_ALL)
    
        min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'
        max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'
    
        # Load processed data using `get_data_with_cache` in chronological order
        # Try it out manually on console.cloud.google.com first!
    
        query = f"""
            SELECT * EXEPT(_0)
            FROM {GCP_PROJECT_WAGON}.{BQ_DATASET}.processed_{DATA_SIZE}
            WHERE _0 BETWEEN '{min_date}' AND '{max_date}'
            ORDER BY _0 ASC
        """
        data_processed_cache_path = Path(LOCAL_DATA_PATH).joinpath("processed", f"processed_{min_date}_{max_date}_{DATA_SIZE}.csv")
        data_processed= get_data_with_cache(query=query,
                                        gcp_project= GCP_PROJECT,
                                        cache_path=data_processed_cache_path,
                                        data_has_header=False)
        if data_processed.shape[0] <10:
            print('not enough data to train on')
            return None
    
        # Create (X_train_processed, y_train, X_val_processed, y_val)
        train_length = int(len(data_processed) * (1 - split_ratio))
        data_processed_train = data_processed.iloc[:train_length, :].sample(frac=1).to_numpy()
        data_processed_val = data_processed.iloc[train_length:, :].sample(frac=1).to_numpy()
    
>       X_train_processed = data_processed_train.drop("fare_amount", axis=1)
E       AttributeError: 'numpy.ndarray' object has no attribute 'drop'

taxifare/interface/main.py:113: AttributeError
----------------------------- Captured stdout call -----------------------------
[35m
‚≠êÔ∏è Use case: train[0m
[34m
Loading preprocessed validation data...[0m
[34m
Load data from local CSV...[0m
‚úÖ Data loaded, with shape (447, 66)
----------------------------- Captured stderr call -----------------------------
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  153k  100  153k    0     0  1275k      0 --:--:-- --:--:-- --:--:-- 1282k
_________________________ TestMain.test_route_evaluate _________________________

self = <tests.cloud_training.test_main.TestMain object at 0x7fe1c89a25f0>

    @patch("taxifare.params.MODEL_TARGET", new='local')
    def test_route_evaluate(self):
        from taxifare.interface.main import evaluate
    
>       mae = evaluate(min_date=MIN_DATE, max_date=MAX_DATE)

tests/cloud_training/test_main.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

min_date = '2009-01-01', max_date = '2015-01-01', stage = 'Production'

    def evaluate(
            min_date:str = '2014-01-01',
            max_date:str = '2015-01-01',
            stage: str = "Production"
        ) -> float:
        """
        Evaluate the performance of the latest production model on processed data
        Return MAE as a float
        """
        print(Fore.MAGENTA + "\n‚≠êÔ∏è Use case: evaluate" + Style.RESET_ALL)
    
        model = load_model(stage=stage)
>       assert model is not None
E       AssertionError

taxifare/interface/main.py:165: AssertionError
----------------------------- Captured stdout call -----------------------------
[35m
‚≠êÔ∏è Use case: evaluate[0m
[34m
Load latest model from local registry...[0m
___________________________ TestMain.test_route_pred ___________________________

self = <tests.cloud_training.test_main.TestMain object at 0x7fe1c89a28f0>

    @patch("taxifare.params.MODEL_TARGET", new='local')
    def test_route_pred(self):
        from taxifare.interface.main import pred
    
>       y_pred = pred()

tests/cloud_training/test_main.py:115: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X_pred =             pickup_datetime  ...  passenger_count
0 2013-07-06 17:18:00+00:00  ...                1

[1 rows x 6 columns]

    def pred(X_pred: pd.DataFrame = None) -> np.ndarray:
        """
        Make a prediction using the latest trained model
        """
    
        print("\n‚≠êÔ∏è Use case: predict")
    
        if X_pred is None:
            X_pred = pd.DataFrame(dict(
            pickup_datetime=[pd.Timestamp("2013-07-06 17:18:00", tz='UTC')],
            pickup_longitude=[-73.950655],
            pickup_latitude=[40.783282],
            dropoff_longitude=[-73.984365],
            dropoff_latitude=[40.769802],
            passenger_count=[1],
        ))
    
        model = load_model()
>       assert model is not None
E       AssertionError

taxifare/interface/main.py:225: AssertionError
----------------------------- Captured stdout call -----------------------------

‚≠êÔ∏è Use case: predict
[34m
Load latest model from local registry...[0m
________________________________ test_i_am_a_vm ________________________________

    def test_i_am_a_vm():
        """
        Test that this code is being run from a Google VM named as per env variable 'INSTANCE'
        """
    
>       assert platform.node() == INSTANCE, f"You should be running from your instance named '{INSTANCE}'."
E       AssertionError: You should be running from your instance named 'taxi-instance'.
E       assert 'DESKTOP-8OFTMTN' == 'taxi-instance'
E         
E         - taxi-instance
E         + DESKTOP-8OFTMTN

tests/cloud_training/test_vm.py:9: AssertionError
=========================== short test summary info ============================
FAILED tests/cloud_training/test_main.py::TestMain::test_route_train[local]
FAILED tests/cloud_training/test_main.py::TestMain::test_route_train[gcs] - A...
FAILED tests/cloud_training/test_main.py::TestMain::test_route_evaluate - Ass...
FAILED tests/cloud_training/test_main.py::TestMain::test_route_pred - Asserti...
FAILED tests/cloud_training/test_vm.py::test_i_am_a_vm - AssertionError: You ...
========================= 5 failed, 4 passed in 19.68s =========================
